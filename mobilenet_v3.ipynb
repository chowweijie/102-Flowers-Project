{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet V3 Large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\tf1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "tfds.core.DatasetInfo(\n",
      "    name='oxford_flowers102',\n",
      "    full_name='oxford_flowers102/2.1.1',\n",
      "    description=\"\"\"\n",
      "    The Oxford Flowers 102 dataset is a consistent of 102 flower categories commonly\n",
      "    occurring in the United Kingdom. Each class consists of between 40 and 258\n",
      "    images. The images have large scale, pose and light variations. In addition,\n",
      "    there are categories that have large variations within the category and several\n",
      "    very similar categories.\n",
      "    \n",
      "    The dataset is divided into a training set, a validation set and a test set. The\n",
      "    training set and validation set each consist of 10 images per class (totalling\n",
      "    1020 images each). The test set consists of the remaining 6149 images (minimum\n",
      "    20 per class).\n",
      "    \n",
      "    Note: The dataset by default comes with a test size larger than the train size.\n",
      "    For more info see this\n",
      "    [issue](https://github.com/tensorflow/datasets/issues/3022).\n",
      "    \"\"\",\n",
      "    homepage='https://www.robots.ox.ac.uk/~vgg/data/flowers/102/',\n",
      "    data_dir='C:\\\\Users\\\\User\\\\tensorflow_datasets\\\\oxford_flowers102\\\\2.1.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=331.34 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'file_name': Text(shape=(), dtype=string),\n",
      "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=102),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=6149, num_shards=2>,\n",
      "        'train': <SplitInfo num_examples=1020, num_shards=1>,\n",
      "        'validation': <SplitInfo num_examples=1020, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@InProceedings{Nilsback08,\n",
      "       author = \"Nilsback, M-E. and Zisserman, A.\",\n",
      "       title = \"Automated Flower Classification over a Large Number of Classes\",\n",
      "       booktitle = \"Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing\",\n",
      "       year = \"2008\",\n",
      "       month = \"Dec\"\n",
      "    }\"\"\",\n",
      ")\n",
      "Number of classes: 102\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    'oxford_flowers102',\n",
    "    split=['test', 'validation', 'train'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,  # Include labels\n",
    "    with_info=True\n",
    ")\n",
    "print(f\"Dataset Info:\\n{ds_info}\")\n",
    "num_classes = ds_info.features['label'].num_classes\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224  # You can adjust this size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def preprocess(image, label):\n",
    "    # Resize and normalize images\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    # image = image / 255.0  # Normalize to [0,1]\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_val = ds_val.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use V3 base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_model = keras.applications.MobileNetV3Large(\n",
    "    weights='imagenet',     # Use 'imagenet' for pre-trained weights, or None\n",
    "    include_top=False,      # Exclude the top classification layers\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "v3_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap it layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " MobilenetV3large (Functiona  (None, 7, 7, 960)        2996352   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 960)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 102)               98022     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,094,374\n",
      "Trainable params: 98,022\n",
      "Non-trainable params: 2,996,352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(224, 224, 3))\n",
    "x = preprocess_input(inputs)\n",
    "x = v3_model(inputs, training=False)  # Set training=False if base_model is frozen\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(102, activation='softmax')(x)  # Adjust the number of classes\n",
    "model = models.Model(inputs, x)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        patience=50, restore_best_weights=True),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'best_model.keras', save_best_only=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 12s 82ms/step - loss: 2.5404 - accuracy: 0.4750 - val_loss: 1.4469 - val_accuracy: 0.7343\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 7s 71ms/step - loss: 0.7803 - accuracy: 0.8792 - val_loss: 0.8055 - val_accuracy: 0.8598\n",
      "Epoch 3/10\n",
      "86/97 [=========================>....] - ETA: 0s - loss: 0.4315 - accuracy: 0.9442"
     ]
    }
   ],
   "source": [
    "epochs = 10  # Adjust the number of epochs as needed\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(ds_test)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
